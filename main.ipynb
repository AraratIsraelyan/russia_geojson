{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a7bef1-a64a-410c-8668-beaed552dd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopandas osmium geojson chardet pyogrio pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0dfb18c-6cfa-4b4e-8db2-04ded7b7d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON файл успешно сохранен в pyatigorsk.geojson\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# URL Overpass API\n",
    "url = \"https://overpass-api.de/api/interpreter\"\n",
    "\n",
    "# Запрос в формате Overpass QL\n",
    "query = \"\"\"\n",
    "[out:json];\n",
    "area[name=\"Пятигорск\"];\n",
    "(\n",
    "  relation(area)[type=multipolygon];\n",
    ");\n",
    "out body;\n",
    ">;\n",
    "out skel qt;\n",
    "\"\"\"\n",
    "\n",
    "# Выполнение запроса\n",
    "response = requests.get(url, params={'data': query})\n",
    "\n",
    "# Проверка на успешное выполнение запроса\n",
    "if response.status_code == 200:\n",
    "    geojson_data = response.json()\n",
    "else:\n",
    "    raise Exception(f\"Ошибка запроса: {response.status_code}\")\n",
    "\n",
    "# Сохранение данных в файл\n",
    "with open(\"pyatigorsk.geojson\", \"w\", encoding='utf-8') as f:\n",
    "    json.dump(geojson_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"GeoJSON файл успешно сохранен в pyatigorsk.geojson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73bbf33c-841a-4e0e-99eb-33394585def9",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "'pyatigorsk.geojson' not recognized as a supported file format. It might help to specify the correct driver explicitly by prefixing the file path with '<DRIVER>:', e.g. 'CSV:path'.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mDataSourceError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyarrow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparquet\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpq\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Загрузка GeoJSON файла в GeoDataFrame\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m gdf \u001B[38;5;241m=\u001B[39m \u001B[43mgpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpyatigorsk.geojson\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Сохранение в формат Parquet\u001B[39;00m\n\u001B[0;32m     10\u001B[0m gdf\u001B[38;5;241m.\u001B[39mto_parquet(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyatigorsk.parquet\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001B[0m, in \u001B[0;36m_read_file\u001B[1;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001B[0m\n\u001B[0;32m    291\u001B[0m             from_bytes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyogrio\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_file_pyogrio\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    298\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfiona\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m pd\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mtypes\u001B[38;5;241m.\u001B[39mis_file_like(filename):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001B[0m, in \u001B[0;36m_read_file_pyogrio\u001B[1;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001B[0m\n\u001B[0;32m    538\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    539\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minclude_fields\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore_fields\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m keywords are deprecated, and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwill be removed in a future release. You can use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m keyword \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    543\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[0;32m    544\u001B[0m     )\n\u001B[0;32m    545\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minclude_fields\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 547\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpyogrio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_bytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\geopandas.py:261\u001B[0m, in \u001B[0;36mread_dataframe\u001B[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_arrow:\n\u001B[0;32m    257\u001B[0m     \u001B[38;5;66;03m# For arrow, datetimes are read as is.\u001B[39;00m\n\u001B[0;32m    258\u001B[0m     \u001B[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001B[39;00m\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# as numpy does not directly support timezones.\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatetime_as_string\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 261\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mread_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    262\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    266\u001B[0m \u001B[43m    \u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_geometry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgdal_force_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql_dialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfid_as_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_arrow:\n\u001B[0;32m    281\u001B[0m     meta, table \u001B[38;5;241m=\u001B[39m result\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:196\u001B[0m, in \u001B[0;36mread\u001B[1;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001B[0m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \n\u001B[0;32m     58\u001B[0m \u001B[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    191\u001B[0m \n\u001B[0;32m    192\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    194\u001B[0m dataset_kwargs \u001B[38;5;241m=\u001B[39m _preprocess_options_key_value(kwargs) \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[1;32m--> 196\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mogr_read\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[43m    \u001B[49m\u001B[43mget_vsi_path_or_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread_geometry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    203\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskip_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    204\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_features\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbbox\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_mask_to_wkb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m    \u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msql_dialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_fids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdatetime_as_string\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdatetime_as_string\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\_io.pyx:1239\u001B[0m, in \u001B[0;36mpyogrio._io.ogr_read\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\_io.pyx:215\u001B[0m, in \u001B[0;36mpyogrio._io.ogr_open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mDataSourceError\u001B[0m: 'pyatigorsk.geojson' not recognized as a supported file format. It might help to specify the correct driver explicitly by prefixing the file path with '<DRIVER>:', e.g. 'CSV:path'."
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Загрузка GeoJSON файла в GeoDataFrame\n",
    "gdf = gpd.read_file(\"pyatigorsk.geojson\")\n",
    "\n",
    "# Сохранение в формат Parquet\n",
    "gdf.to_parquet(\"pyatigorsk.parquet\")\n",
    "\n",
    "print(\"Parquet файл успешно сохранен в pyatigorsk.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a182a1-3d8e-4f97-be55-c3580f202fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8852477b6741aea7"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m spark_session\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# Создание Spark сессии\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m spark \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_spark_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# Проверка создания сессии\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpark session created:\u001B[39m\u001B[38;5;124m\"\u001B[39m, spark)\n",
      "Cell \u001B[1;32mIn[1], line 16\u001B[0m, in \u001B[0;36mcreate_spark_session\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_spark_session\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m SparkSession:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# Конфигурация для использования одного ядра, 4GB памяти для драйвера и порта 4043 для Spark UI\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     conf \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m      7\u001B[0m         SparkConf()\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.driver.memory\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m4g\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m         \u001B[38;5;241m.\u001B[39mset(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspark.ui.port\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m4046\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# Установка порта для Spark UI\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     )\n\u001B[0;32m     12\u001B[0m     spark_session \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     13\u001B[0m         \u001B[43mSparkSession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaster\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlocal[1]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Использование одного ядра\u001B[39;49;00m\n\u001B[0;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappName\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSpark UI Tutorial\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m---> 16\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     )\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m spark_session\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\sql\\session.py:497\u001B[0m, in \u001B[0;36mSparkSession.Builder.getOrCreate\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    495\u001B[0m     sparkConf\u001B[38;5;241m.\u001B[39mset(key, value)\n\u001B[0;32m    496\u001B[0m \u001B[38;5;66;03m# This SparkContext may be an existing one.\u001B[39;00m\n\u001B[1;32m--> 497\u001B[0m sc \u001B[38;5;241m=\u001B[39m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetOrCreate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparkConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001B[39;00m\n\u001B[0;32m    499\u001B[0m \u001B[38;5;66;03m# by all sessions.\u001B[39;00m\n\u001B[0;32m    500\u001B[0m session \u001B[38;5;241m=\u001B[39m SparkSession(sc, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_options)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:515\u001B[0m, in \u001B[0;36mSparkContext.getOrCreate\u001B[1;34m(cls, conf)\u001B[0m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    514\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 515\u001B[0m         \u001B[43mSparkContext\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mSparkConf\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    516\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    517\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_active_spark_context\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:201\u001B[0m, in \u001B[0;36mSparkContext.__init__\u001B[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gateway \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m gateway\u001B[38;5;241m.\u001B[39mgateway_parameters\u001B[38;5;241m.\u001B[39mauth_token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    197\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    198\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not allowed as it is a security risk.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    199\u001B[0m     )\n\u001B[1;32m--> 201\u001B[0m \u001B[43mSparkContext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_ensure_initialized\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgateway\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgateway\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_init(\n\u001B[0;32m    204\u001B[0m         master,\n\u001B[0;32m    205\u001B[0m         appName,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    215\u001B[0m         memory_profiler_cls,\n\u001B[0;32m    216\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\context.py:436\u001B[0m, in \u001B[0;36mSparkContext._ensure_initialized\u001B[1;34m(cls, instance, gateway, conf)\u001B[0m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m SparkContext\u001B[38;5;241m.\u001B[39m_gateway:\n\u001B[1;32m--> 436\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_gateway \u001B[38;5;241m=\u001B[39m gateway \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mlaunch_gateway\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    437\u001B[0m         SparkContext\u001B[38;5;241m.\u001B[39m_jvm \u001B[38;5;241m=\u001B[39m SparkContext\u001B[38;5;241m.\u001B[39m_gateway\u001B[38;5;241m.\u001B[39mjvm\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m instance:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\java_gateway.py:104\u001B[0m, in \u001B[0;36mlaunch_gateway\u001B[1;34m(conf, popen_kwargs)\u001B[0m\n\u001B[0;32m    102\u001B[0m \u001B[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001B[39;00m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpoll() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(conn_info_file):\n\u001B[1;32m--> 104\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misfile(conn_info_file):\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkRuntimeError(\n\u001B[0;32m    108\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJAVA_GATEWAY_EXITED\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    109\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{},\n\u001B[0;32m    110\u001B[0m     )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def create_spark_session() -> SparkSession:\n",
    "    # Конфигурация для использования одного ядра, 4GB памяти для драйвера и порта 4043 для Spark UI\n",
    "    conf = (\n",
    "        SparkConf()\n",
    "        .set(\"spark.driver.memory\", \"4g\")\n",
    "        .set(\"spark.ui.port\", \"4046\")  # Установка порта для Spark UI\n",
    "    )\n",
    "\n",
    "    spark_session = (\n",
    "        SparkSession.builder.master(\"local[1]\")  # Использование одного ядра\n",
    "        .config(conf=conf)\n",
    "        .appName(\"Spark UI Tutorial\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "    return spark_session\n",
    "\n",
    "# Создание Spark сессии\n",
    "spark = create_spark_session()\n",
    "\n",
    "# Проверка создания сессии\n",
    "print(\"Spark session created:\", spark)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:11:29.560578300Z",
     "start_time": "2024-08-14T08:00:52.731454700Z"
    }
   },
   "id": "b26a6dd2e7ab7384",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = fr\"C:\\Program Files\\Java\\jdk-21\"\n",
    "# os.environ[\"SPARK_HOME\"] = \"C:\\Program Files\\Spark\\spark-3.3.1-bin-hadoop2\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:14:26.151518900Z",
     "start_time": "2024-08-14T08:14:26.119348400Z"
    }
   },
   "id": "9a6a794a3be9493f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Program Files\\\\Java\\\\jdk-21'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"JAVA_HOME\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:14:31.770086500Z",
     "start_time": "2024-08-14T08:14:31.740769Z"
    }
   },
   "id": "2a931caf99cc248a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Detecting-Malicious-URL App\").getOrCreate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:14:42.230609Z",
     "start_time": "2024-08-14T08:14:34.797204700Z"
    }
   },
   "id": "a1a9809f1cb8fb3c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<pyspark.sql.session.SparkSession at 0x23e7f1b1b50>",
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://MagicBook:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Detecting-Malicious-URL App</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:15:35.505865200Z",
     "start_time": "2024-08-14T08:15:33.739399500Z"
    }
   },
   "id": "4f602112a5d66c48",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-14T08:15:57.577541200Z",
     "start_time": "2024-08-14T08:15:57.014563500Z"
    }
   },
   "id": "ce5195391d5b2a60",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69e50184a91bcec6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
